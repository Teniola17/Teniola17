{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Teniola17/Teniola17/blob/main/KL1_Estimator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **LIBRARY AND FUNCTIONS**"
      ],
      "metadata": {
        "id": "xCv8u_pEzFqj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "I31OacBvNr9F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb1bfe55-d6b6-45e0-b49b-696a1d12ab82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-17a6d506fd40>:13: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
            "  style.use('seaborn-colorblind')\n",
            "<ipython-input-1-17a6d506fd40>:16: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
            "  plt.style.use('seaborn-white')\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from mpl_toolkits import mplot3d\n",
        "from sklearn import linear_model\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import files\n",
        "import random\n",
        "from sklearn.model_selection import KFold\n",
        "import matplotlib.style as style\n",
        "style.use('seaborn-colorblind')\n",
        "\n",
        "%matplotlib inline\n",
        "plt.style.use('seaborn-white')\n",
        "\n",
        "def soft_threshold(rho,lamda):\n",
        "    '''Soft threshold function used for normalized data and lasso regression'''\n",
        "    if rho < - lamda:\n",
        "        return (rho + lamda)\n",
        "    elif rho >  lamda:\n",
        "        return (rho - lamda)\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "#tolerance\n",
        "def tolerance(init_res, fin_res):\n",
        "    diff = fin_res - init_res\n",
        "    est_tol = diff.T @ diff\n",
        "    return(est_tol.reshape(-1)[0])\n",
        "\n",
        "def coordinate_descent_lasso(X,y,lamda = .01, num_iters=100, intercept = False, tol = 1e-10):\n",
        "    '''Coordinate gradient descent for lasso regression - for normalized data.\n",
        "    The intercept parameter allows to specify whether or not we regularize theta_0'''\n",
        "\n",
        "    #Initialisation of useful values\n",
        "    m,n = X.shape\n",
        "\n",
        "    old_theta = np.linalg.inv(X.T @ X + np.identity(n)*lamda) @ (X.T @ y)\n",
        "\n",
        "    #Looping until max number of iterations\n",
        "    for i in range(num_iters):\n",
        "        theta = old_theta\n",
        "        #Looping through each coordinate\n",
        "        for j in range(n):\n",
        "            #Vectorized implementation\n",
        "            X_j = X[:,j].reshape(-1,1)\n",
        "            y_pred = X @ theta\n",
        "            rho = X_j.T @ (y - y_pred  + theta[j]*X_j)\n",
        "            c = sum(X[:,j]**2)\n",
        "\n",
        "            #Checking intercept parameter\n",
        "            if c == 0:\n",
        "                theta[j] =  0\n",
        "            else:\n",
        "              if intercept == True:\n",
        "                  if j == 0:\n",
        "                      theta[j] =  rho\n",
        "                  else:\n",
        "                      theta[j] =  soft_threshold(rho/c, lamda/c)\n",
        "\n",
        "              if intercept == False:\n",
        "                  theta[j] =  soft_threshold(rho/c, lamda/c)\n",
        "\n",
        "        est_tol = tolerance(old_theta, theta)\n",
        "        if est_tol < tol:\n",
        "          break\n",
        "        else:\n",
        "          old_theta = theta\n",
        "    return theta.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6FXhbVJKvxMW"
      },
      "outputs": [],
      "source": [
        "def coordinate_descent_liulasso(X,y,lamda = .01, d=0.3, num_iters=100, intercept = False, tol = 1e-10):\n",
        "    '''Coordinate gradient descent for lasso regression - for normalized data.\n",
        "    The intercept parameter allows to specify whether or not we regularize theta_0'''\n",
        "\n",
        "    #Initialisation of useful values\n",
        "    m,n = X.shape\n",
        "\n",
        "    old_theta = np.linalg.inv(X.T @ X + np.identity(n)*lamda) @ (X.T @ y)\n",
        "\n",
        "    #Looping until max number of iterations\n",
        "    for i in range(num_iters):\n",
        "        theta = old_theta\n",
        "        #Looping through each                               coordinate\n",
        "        for j in range(n):\n",
        "\n",
        "            #Vectorized implementation\n",
        "            X_j = X[:,j].reshape(-1,1)\n",
        "            y_pred = X @ theta\n",
        "            rho = X_j.T @ (y - y_pred  + theta[j]*X_j)+d*theta[j]\n",
        "\n",
        "            #Checking intercept parameter\n",
        "            if intercept == True:\n",
        "                if j == 0:\n",
        "                    theta[j] =  rho\n",
        "                else:\n",
        "                    theta[j] =  soft_threshold(rho/(1+sum(X[:, j]**2)), lamda/(1+sum(X[:, j]**2)))\n",
        "\n",
        "            if intercept == False:\n",
        "                theta[j] =  soft_threshold(rho/(1+sum(X[:, j]**2)), lamda/(1+sum(X[:, j]**2)))\n",
        "\n",
        "        est_tol = tolerance(old_theta, theta)\n",
        "        if est_tol < tol:\n",
        "          break\n",
        "        else:\n",
        "          old_theta = theta\n",
        "\n",
        "    return theta.flatten()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5ldtJCx6TdZM"
      },
      "outputs": [],
      "source": [
        "def coordinate_descent_goest(X, y, lamda = .01, alpha = .5, num_iters=100, intercept = False, tol = 1e-10):\n",
        "    '''Coordinate gradient descent for lasso regression - for normalized data.\n",
        "    The intercept parameter allows to specify whether or not we regularize theta_0'''\n",
        "\n",
        "    #Initialisation of useful values\n",
        "    m,n = X.shape\n",
        "\n",
        "    old_theta = np.linalg.inv(X.T @ X + np.identity(n)*lamda) @ (X.T @ y)\n",
        "\n",
        "    #Looping until max number of iterations\n",
        "    for i in range(num_iters):\n",
        "        theta = old_theta\n",
        "        #Looping through each                               coordinate\n",
        "        for j in range(n):\n",
        "\n",
        "            #Vectorized implementation\n",
        "            X_j = X[:,j].reshape(-1,1)\n",
        "            y_pred = X @ theta\n",
        "            rho = X_j.T @ (y - y_pred  + theta[j]*X_j)+lamda*(1-alpha)*theta[j]\n",
        "\n",
        "            #Checking intercept parameter\n",
        "            if intercept == True:\n",
        "                if j == 0:\n",
        "                    theta[j] =  rho\n",
        "                else:\n",
        "                    theta[j] =  soft_threshold(rho/((lamda*(1-alpha))+sum(X[:, j]**2)), (lamda*alpha)/((lamda*(1-alpha))+sum(X[:, j]**2)))\n",
        "\n",
        "            if intercept == False:\n",
        "                theta[j] =  soft_threshold(rho/((lamda*(1-alpha))+sum(X[:, j]**2)), (lamda*alpha)/((lamda*(1-alpha))+sum(X[:, j]**2)))\n",
        "\n",
        "        est_tol = tolerance(old_theta, theta)\n",
        "        if est_tol < tol:\n",
        "          break\n",
        "        else:\n",
        "          old_theta = theta\n",
        "\n",
        "    return theta.flatten()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5Bk8s_tjVl_I"
      },
      "outputs": [],
      "source": [
        "def coordinate_descent_enet(X,y,lamda = .01, alpha = 0.5, num_iters=100, intercept = False, tol = 1e-10):\n",
        "    '''Coordinate gradient descent for lasso regression - for normalized data.\n",
        "    The intercept parameter allows to specify whether or not we regularize theta_0'''\n",
        "\n",
        "    #Initialisation of useful values\n",
        "    m,n = X.shape\n",
        "\n",
        "    old_theta = np.linalg.inv(X.T @ X + np.identity(n)*lamda) @ (X.T @ y)\n",
        "\n",
        "    #Looping until max number of iterations\n",
        "    for i in range(num_iters):\n",
        "        theta = old_theta\n",
        "        #Looping through each                               coordinate\n",
        "        for j in range(n):\n",
        "\n",
        "            #Vectorized implementation\n",
        "            X_j = X[:,j].reshape(-1,1)\n",
        "            y_pred = X @ theta\n",
        "            rho = X_j.T @ (y - y_pred  + theta[j]*X_j)+lamda*alpha\n",
        "\n",
        "            #Checking intercept parameter\n",
        "            if intercept == True:\n",
        "                if j == 0:\n",
        "                    theta[j] =  rho\n",
        "                else:\n",
        "                    theta[j] =  soft_threshold(rho/(sum(X[:, j]**2)+lamda*(1-alpha)), lamda/(sum(X[:, j]**2)+lamda*(1-alpha)))\n",
        "\n",
        "            if intercept == False:\n",
        "                theta[j] =  soft_threshold(rho/(sum(X[:, j]**2)+lamda*(1-alpha)), lamda/(sum(X[:, j]**2)+lamda*(1-alpha)))\n",
        "\n",
        "        est_tol = tolerance(old_theta, theta)\n",
        "        if est_tol < tol:\n",
        "          break\n",
        "        else:\n",
        "          old_theta = theta\n",
        "\n",
        "    return theta.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MZXD3Gft9tKV"
      },
      "outputs": [],
      "source": [
        "def coordinate_descent_KL1(X, y, lamda = .01, num_iters=100, intercept = False, tol = 1e-10):\n",
        "    '''Coordinate gradient descent for lasso regression - for normalized data.\n",
        "    The intercept parameter allows to specify whether or not we regularize theta_0'''\n",
        "\n",
        "    #Initialisation of useful values\n",
        "    m,n = X.shape\n",
        "\n",
        "    old_theta = np.linalg.inv(X.T @ X + np.identity(n)*lamda) @ (X.T @ y)\n",
        "\n",
        "    #Looping until max number of iterations\n",
        "    for i in range(num_iters):\n",
        "        theta = old_theta\n",
        "        #Looping through each                               coordinate\n",
        "        for j in range(n):\n",
        "\n",
        "            #Vectorized implementation\n",
        "            X_j = X[:,j].reshape(-1,1)\n",
        "            y_pred = X @ theta\n",
        "            rho = X_j.T @ (y - y_pred  + theta[j]*X_j)-theta[j]\n",
        "\n",
        "            #Checking intercept parameter\n",
        "            if intercept == True:\n",
        "                if j == 0:\n",
        "                    theta[j] =  rho\n",
        "                else:\n",
        "                    theta[j] =  soft_threshold(rho/(1+sum(X[:, j]**2)), lamda/(1+sum(X[:, j]**2)))\n",
        "\n",
        "            if intercept == False:\n",
        "                theta[j] =  soft_threshold(rho/(1+sum(X[:, j]**2)), lamda/(1+sum(X[:, j]**2)))\n",
        "\n",
        "        est_tol = tolerance(old_theta, theta)\n",
        "        if est_tol < tol:\n",
        "          break\n",
        "        else:\n",
        "          old_theta = theta\n",
        "\n",
        "    return theta.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ES0B_3znAPuc"
      },
      "outputs": [],
      "source": [
        "#OLS, Liu, Ridge and KL Estimators\n",
        "def ridge_estimator(X,y,lamda = .01):\n",
        "  m,n = X.shape\n",
        "  theta = np.linalg.inv(X.T @ X + np.identity(n)*lamda) @ (X.T @ y)\n",
        "  return theta.flatten()\n",
        "\n",
        "def ols_estimator(X,y):\n",
        "  theta = np.linalg.inv(X.T @ X) @ (X.T @ y)\n",
        "  return theta.flatten()\n",
        "\n",
        "def liu_estimator(X,y,d):\n",
        "  m,n = X.shape\n",
        "  old_theta = np.linalg.inv(X.T @ X) @ (X.T @ y)\n",
        "  theta = np.linalg.inv(X.T @ X + np.identity(n)) @ (X.T @ X + np.identity(n)*d) @ old_theta\n",
        "  return theta.flatten()\n",
        "\n",
        "def mliu_estimator(X,y,d):\n",
        "  m,n = X.shape\n",
        "  old_theta = np.linalg.inv(X.T @ X) @ (X.T @ y)\n",
        "  theta = np.linalg.inv(X.T @ X + np.identity(n)) @ (X.T @ X - np.identity(n)*d) @ old_theta\n",
        "  return theta.flatten()\n",
        "\n",
        "def kl_estimator(X,y,lamda):\n",
        "  m,n = X.shape\n",
        "  old_theta = np.linalg.inv(X.T @ X) @ (X.T @ y)\n",
        "  theta = np.linalg.inv(X.T @ X + np.identity(n)*lamda) @ (X.T @ X - np.identity(n)*lamda) @ old_theta\n",
        "  return theta.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tJywDwo1RucJ"
      },
      "outputs": [],
      "source": [
        "#Function to compute mean square error\n",
        "def mse_beta(est_beta, real_beta):\n",
        "    diff = est_beta - real_beta\n",
        "    mse_b = diff.T @ diff\n",
        "    return(mse_b.reshape(-1)[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GRFequeYhza9"
      },
      "outputs": [],
      "source": [
        "#Confusion matrix function for Beta Coefficients\n",
        "def cm_par(est_beta, real_beta):\n",
        "  actual = [1 if i!=0 else 0 for i in real_beta]\n",
        "  predicted = [1 if i!=0 else 0 for i in est_beta]\n",
        "  data = {'beta_predict':predicted, 'beta_actual':actual}\n",
        "  cm_df = pd.DataFrame(data, columns=['beta_actual','beta_predict'])\n",
        "  cm_res = pd.crosstab(cm_df['beta_actual'], cm_df['beta_predict'], rownames=['Actual'], colnames=['Predicted'])#, margins = True)\n",
        "  cm_res_un = cm_res.unstack().reorder_levels(('Actual','Predicted'))\n",
        "  try:\n",
        "    fnr = cm_res_un.loc[1,0]\n",
        "  except:\n",
        "    fnr = np.nan\n",
        "  try:\n",
        "    fpr = cm_res_un.loc[0,1]\n",
        "  except:\n",
        "    fpr = np.nan\n",
        "  return(fnr, fpr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiUm3Yw1ja8F"
      },
      "source": [
        "**SIMULATION: Validation, Training and Test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QAbC_5RrjZ2p"
      },
      "outputs": [],
      "source": [
        "#First Simulation\n",
        "def gen_dat(bet_bb, pp = 10, nn = 30, rho = 0.5, sig=5):\n",
        "  cov = np.zeros((pp,pp))\n",
        "  for i in range(pp):\n",
        "    for j in range(pp):\n",
        "      cov[i,j] = rho**(abs(i - j))\n",
        "  mean = np.zeros(pp)\n",
        "  x_mat = np.random.multivariate_normal(mean, cov, nn)\n",
        "  df_x = pd.DataFrame(x_mat)\n",
        "  eps = np.random.normal(loc = 0.0, scale = sig, size = nn)\n",
        "  y_vec = (x_mat @ bet_bb) + eps\n",
        "  df_x.columns = ['x'+str(i+1) for i in range(pp)]\n",
        "  df_x.insert(0,'y',y_vec)\n",
        "  return df_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yb4WLQe8S68x"
      },
      "outputs": [],
      "source": [
        "#SIMULATION PART - High Dimension\n",
        "#beta_int = np.array([0.5]*15 + [0]*25 + [0.7]*15 + [0]*30 + [0.7]*15) #sim A - 55 zeros\n",
        "#beta_int = np.array([0.5]*15 + [0]*25 + [0]*15 + [0]*30 + [0]*15) #sim B - 85 zeros\n",
        "#beta_int = np.array([0.5]*15 + [0.2]*25 + [0.7]*15 + [0.4]*30 + [0.9]*15) #sim C\n",
        "#sim_p = 100; sim_times = 50; sim_size = [200]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "GghAeMyLBRz2"
      },
      "outputs": [],
      "source": [
        "#SIMULATION PART - Low Dimension\n",
        "#beta_int = np.array([3,1.5,0,0,2,0,0,0])  #sim A\n",
        "#beta_int = np.array([3,0,0,0,0,0,0,0])#sim B\n",
        "beta_int = np.array([3,1.5,2,1.6,2,1.5,1.5,1.5]) #sim C\n",
        "sim_p = 8; sim_times = 50; sim_size = [400]#100, 200, 400]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WarQAAZUjZ95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "outputId": "3dfcb88b-01c0-4727-c99c-7ca45268415d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-aabadf85801b>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0md_p\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m               \u001b[0mlasso_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoordinate_descent_lasso\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m               \u001b[0mliulasso_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoordinate_descent_liulasso\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m               \u001b[0mgoest_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoordinate_descent_goest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-17a6d506fd40>\u001b[0m in \u001b[0;36mcoordinate_descent_lasso\u001b[0;34m(X, y, lamda, num_iters, intercept, tol)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mold_theta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlamda\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;31m#Looping until max number of iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m     \u001b[0mainv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "whole_tab_sim_df = pd.DataFrame(columns=['n','p','rho','sig','stats','lasso', 'liulasso', 'goest', 'enet', 'kl1', 'ridge'])\n",
        "sim_tab_row = 1\n",
        "\n",
        "for sim_sig in [5,10]:\n",
        "  for sim_rho in [0.99]:#0.5,0.8,0.99]:\n",
        "    for sim_n in sim_size:\n",
        "      test_mse_sim_df = pd.DataFrame(columns=['lasso', 'liulasso', 'goest', 'enet', 'kl1', 'ridge'])\n",
        "      beta_mse_sim_df = pd.DataFrame(columns=['lasso', 'liulasso', 'goest', 'enet', 'kl1', 'ridge'])\n",
        "      fpr_sim_df = pd.DataFrame(columns=['lasso', 'liulasso', 'goest', 'enet', 'kl1', 'ridge'])\n",
        "      fnr_sim_df = pd.DataFrame(columns=['lasso', 'liulasso', 'goest', 'enet', 'kl1', 'ridge'])\n",
        "\n",
        "      test_row = 1\n",
        "      for sim_no in range(sim_times):\n",
        "        dat = gen_dat(beta_int, pp = sim_p, nn = sim_n, sig = sim_sig)\n",
        "        dat = dat.to_numpy()\n",
        "        yr = dat[:, 1].reshape(-1, 1)\n",
        "        Xr = np.delete(dat, -1, axis=1)\n",
        "        yr = yr.reshape(yr.shape[0], 1)\n",
        "\n",
        "        xx_trainval, xx_test, yy_trainval, yy_test = train_test_split(Xr, yr, test_size = 0.20, random_state = 15)\n",
        "\n",
        "        xx_train, xx_valid, yy_train, yy_valid = train_test_split(xx_trainval, yy_trainval, test_size = 0.25, random_state = 15)\n",
        "\n",
        "        #Empty dataframe to hold mean and median for each parameter combination\n",
        "        fold_mses_df = pd.DataFrame(columns=['lambda','alpha','d','lasso','liulasso','goest','enet','kl1','ridge'])\n",
        "\n",
        "        row_num = 1\n",
        "        for lam in [0.1*(i+1) for i in range(10)]: #[0.1*(i+1) for i in range(9)]:\n",
        "          for a_p in [0.1*(i+1) for i in range(10)]:\n",
        "            for d_p in [0.1*(i+1) for i in range(10)]:\n",
        "\n",
        "              lasso_mod = coordinate_descent_lasso(xx_train, yy_train, lamda = lam, num_iters=100, intercept = False)\n",
        "              liulasso_mod = coordinate_descent_liulasso(xx_train, yy_train, lamda = lam, d = d_p, num_iters=100, intercept = False)\n",
        "              goest_mod = coordinate_descent_goest(xx_train, yy_train, lamda = lam, alpha = a_p, num_iters=100, intercept = False)\n",
        "              enet_mod = coordinate_descent_enet(xx_train, yy_train, lamda = lam, alpha = a_p, num_iters=100, intercept = False)\n",
        "              kl1_mod = coordinate_descent_KL1(xx_train, yy_train, lamda = lam, num_iters=100, intercept = False)\n",
        "              ridge_mod = ridge_estimator(xx_train, yy_train, lamda = lam)\n",
        "\n",
        "              msel_lasso = np.square(np.subtract(yy_valid,xx_valid@lasso_mod)).mean()\n",
        "              msel_liulasso = np.square(np.subtract(yy_valid,xx_valid@liulasso_mod)).mean()\n",
        "              msel_goest = np.square(np.subtract(yy_valid,xx_valid@goest_mod)).mean()\n",
        "              msel_enet = np.square(np.subtract(yy_valid,xx_valid@enet_mod)).mean()\n",
        "              msel_kl1 = np.square(np.subtract(yy_valid,xx_valid@kl1_mod)).mean()\n",
        "              msel_ridge = np.square(np.subtract(yy_valid,xx_valid@ridge_mod)).mean()\n",
        "\n",
        "              fold_mses_df.loc[row_num] = [lam, a_p, d_p, msel_lasso, msel_liulasso, msel_goest, msel_enet, msel_kl1, msel_ridge]\n",
        "\n",
        "              row_num+=1\n",
        "\n",
        "        all_estimators_names = ['lasso','liulasso','goest','enet','klenet','kl1','kl2','goestd','kl3','kl4','ridge']\n",
        "\n",
        "        lam, d_p, a_p = fold_mses_df.loc[fold_mses_df[all_estimators_names[0]].idxmin()].to_list()[0:3]\n",
        "        lasso_modt = coordinate_descent_lasso(xx_trainval, yy_trainval, lamda = lam, num_iters=100, intercept = False)\n",
        "\n",
        "        lam, d_p, a_p = fold_mses_df.loc[fold_mses_df[all_estimators_names[1]].idxmin()].to_list()[0:3]\n",
        "        liulasso_modt = coordinate_descent_liulasso(xx_trainval, yy_trainval, lamda = lam, d = d_p, num_iters=100, intercept = False)\n",
        "\n",
        "        lam, d_p, a_p = fold_mses_df.loc[fold_mses_df[all_estimators_names[2]].idxmin()].to_list()[0:3]\n",
        "        goest_modt = coordinate_descent_goest(xx_trainval, yy_trainval, lamda = lam, alpha = a_p, num_iters=100, intercept = False)\n",
        "\n",
        "        lam, d_p, a_p = fold_mses_df.loc[fold_mses_df[all_estimators_names[3]].idxmin()].to_list()[0:3]\n",
        "        enet_modt = coordinate_descent_enet(xx_trainval, yy_trainval, lamda = lam, alpha = a_p, num_iters=100, intercept = False)\n",
        "\n",
        "        lam, d_p, a_p = fold_mses_df.loc[fold_mses_df[all_estimators_names[5]].idxmin()].to_list()[0:3]\n",
        "        kl1_modt = coordinate_descent_KL1(xx_trainval, yy_trainval, lamda = lam, num_iters=100, intercept = False)\n",
        "\n",
        "        lam, d_p, a_p = fold_mses_df.loc[fold_mses_df[all_estimators_names[10]].idxmin()].to_list()[0:3]\n",
        "        ridge_modt = ridge_estimator(xx_trainval, yy_trainval, lamda = lam)\n",
        "\n",
        "        #Estimate MSE BETA\n",
        "        mseb_lasso = mse_beta(lasso_modt, beta_int)\n",
        "        mseb_liulasso = mse_beta(liulasso_modt, beta_int)\n",
        "        mseb_goest = mse_beta(goest_modt, beta_int)\n",
        "        mseb_enet = mse_beta(enet_modt, beta_int)\n",
        "        mseb_kl1 = mse_beta(kl1_modt, beta_int)\n",
        "        mseb_ridge = mse_beta(ridge_modt, beta_int)\n",
        "        beta_mse_sim_df.loc[test_row] = [mseb_lasso, mseb_liulasso, mseb_goest, mseb_enet, mseb_kl1, mseb_ridge]\n",
        "\n",
        "        #False Negative and False Positve\n",
        "        fnr_lasso, fpr_lasso = cm_par(lasso_modt, beta_int)\n",
        "        fnr_liulasso, fpr_liulasso = cm_par(liulasso_modt, beta_int)\n",
        "        fnr_goest, fpr_goest = cm_par(goest_modt, beta_int)\n",
        "        fnr_enet, fpr_enet = cm_par(enet_modt, beta_int)\n",
        "        fnr_kl1, fpr_kl1 = cm_par(kl1_modt, beta_int)\n",
        "        fnr_ridge, fpr_ridge = cm_par(ridge_modt, beta_int) #(np.nan, np.nan)\n",
        "        fnr_sim_df.loc[test_row] = [fnr_lasso, fnr_liulasso, fnr_goest, fnr_enet, fnr_kl1, fnr_ridge]\n",
        "        fpr_sim_df.loc[test_row] = [fpr_lasso, fpr_liulasso, fpr_goest, fpr_enet, fpr_kl1, fpr_ridge]\n",
        "\n",
        "        #Estimate MSE on Y\n",
        "        mset_lasso = np.square(np.subtract(yy_test,xx_test@lasso_modt)).mean()\n",
        "        mset_liulasso = np.square(np.subtract(yy_test,xx_test@liulasso_modt)).mean()\n",
        "        mset_goest = np.square(np.subtract(yy_test,xx_test@goest_modt)).mean()\n",
        "        mset_enet = np.square(np.subtract(yy_test,xx_test@enet_modt)).mean()\n",
        "        mset_kl1 = np.square(np.subtract(yy_test,xx_test@kl1_modt)).mean()\n",
        "        mset_ridge = np.square(np.subtract(yy_test,xx_test@ridge_modt)).mean()\n",
        "        test_mse_sim_df.loc[test_row] = [mset_lasso, mset_liulasso, mset_goest, mset_enet, mset_kl1, mset_ridge]\n",
        "        test_row+=1\n",
        "\n",
        "      fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "      beta_mse_sim_df.plot(kind='box', fontsize=14, ax=ax1)#, color=dict(boxes='blue', whiskers='blue', medians='green', caps='blue'))\n",
        "      ax1.set_ylabel(r'$\\beta$'+'-MSE',fontdict={'fontsize':15}), ax1.tick_params(axis='x', labelrotation=45)\n",
        "      test_mse_sim_df.plot(kind='box', fontsize=14, ax=ax2)#, color=dict(boxes='blue', whiskers='blue', medians='green', caps='blue')) grid=True\n",
        "      ax2.set_ylabel('TMSE',fontdict={'fontsize':15}), ax2.tick_params(axis='x', labelrotation=45)\n",
        "      plt.savefig(str(sim_n)+\"_\"+str(sim_p)+\"_\"+str(sim_rho)+\"_\"+str(sim_sig)+\".png\")\n",
        "      files.download(str(sim_n)+\"_\"+str(sim_p)+\"_\"+str(sim_rho)+\"_\"+str(sim_sig)+\".png\")\n",
        "\n",
        "      whole_tab_sim_df.loc[sim_tab_row] = [sim_n,sim_p,sim_rho,sim_sig,\"Beta_med\"] + beta_mse_sim_df.median().to_list()\n",
        "      whole_tab_sim_df.loc[sim_tab_row+1] = [sim_n,sim_p,sim_rho,sim_sig,\"Beta_mean\"] + beta_mse_sim_df.mean().to_list()\n",
        "      whole_tab_sim_df.loc[sim_tab_row+2] = [sim_n,sim_p,sim_rho,sim_sig,\"Beta_sem\"] + beta_mse_sim_df.sem().to_list()\n",
        "\n",
        "      whole_tab_sim_df.loc[sim_tab_row+3] = [sim_n,sim_p,sim_rho,sim_sig,\"Test_med\"] + test_mse_sim_df.median().to_list()\n",
        "      whole_tab_sim_df.loc[sim_tab_row+4] = [sim_n,sim_p,sim_rho,sim_sig,\"Test_mean\"] + test_mse_sim_df.mean().to_list()\n",
        "      whole_tab_sim_df.loc[sim_tab_row+5] = [sim_n,sim_p,sim_rho,sim_sig,\"Test_sem\"] + test_mse_sim_df.sem().to_list()\n",
        "\n",
        "      whole_tab_sim_df.loc[sim_tab_row+6] = [sim_n,sim_p,sim_rho,sim_sig,\"fnr\"] + fnr_sim_df.median().to_list()\n",
        "      whole_tab_sim_df.loc[sim_tab_row+7] = [sim_n,sim_p,sim_rho,sim_sig,\"fpr\"] + fpr_sim_df.median().to_list()\n",
        "      whole_tab_sim_df.loc[sim_tab_row+8] = ['n','p','rho','sig','stat','lasso', 'liulasso', 'goest', 'enet', 'kl1', 'ridge']\n",
        "\n",
        "      sim_tab_row+=9\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JkOJ482MGNYH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "4540bfe7-48a6-4f01-d8ee-61ac3efaa5c2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2f00f9db-3ac7-406b-b297-22d4eca4ffb9\", \"whole_tab_sim_dff.csv\", 58)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "pd.DataFrame(whole_tab_sim_df).to_csv('whole_tab_sim_dff.csv', encoding = 'utf-8-sig')\n",
        "files.download('whole_tab_sim_dff.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "axHTMllEjaEM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "526fe2c2-0837-47d4-9655-2fb879dc3fcb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [n, p, rho, sig, stats, lasso, liulasso, goest, enet, kl1, ridge]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7fbe0faa-db04-43eb-805b-c38e2c252b8f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n</th>\n",
              "      <th>p</th>\n",
              "      <th>rho</th>\n",
              "      <th>sig</th>\n",
              "      <th>stats</th>\n",
              "      <th>lasso</th>\n",
              "      <th>liulasso</th>\n",
              "      <th>goest</th>\n",
              "      <th>enet</th>\n",
              "      <th>kl1</th>\n",
              "      <th>ridge</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7fbe0faa-db04-43eb-805b-c38e2c252b8f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7fbe0faa-db04-43eb-805b-c38e2c252b8f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7fbe0faa-db04-43eb-805b-c38e2c252b8f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "whole_tab_sim_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ep7ylibxBeap"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRrkcuGNIQgU"
      },
      "source": [
        "**PRACTICAL APPLICATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "gb1KocqDRp0v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "24f3a3fc-47e8-4784-b070-0b0e3db84894"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b0974750-af00-4150-a0d8-65198133e419\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b0974750-af00-4150-a0d8-65198133e419\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving anti.csv to anti.csv\n"
          ]
        }
      ],
      "source": [
        "#datasuper=files.upload()\n",
        "#dat=pd.read_csv(\"flu.csv\")\n",
        "#datasuper=files.upload()\n",
        "#dat=pd.read_csv(\"superconduct.csv\")\n",
        "#dataasphalt=files.upload()\n",
        "#dat=pd.read_csv(\"data asphalt.csv\")\n",
        "#prostatedata=files.upload()\n",
        "#dat=pd.read_csv(\"Prostate data.csv\")\n",
        "ahdd=files.upload()\n",
        "dat=pd.read_csv(\"anti.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUvBLjYJQZyd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4Vp2aV4vpRT"
      },
      "source": [
        "**K-Fold Classification Approach**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "oWVovR2rvn2D"
      },
      "outputs": [],
      "source": [
        "# Format Data\n",
        "dat = dat.to_numpy()\n",
        "yr = dat[:, 1].reshape(-1, 1)\n",
        "Xr = np.delete(dat, -1, axis=1)\n",
        "\n",
        "yr = yr.reshape(yr.shape[0], 1)\n",
        "\n",
        "X, xx_test, y, yy_test = train_test_split(Xr, yr, test_size = 0.20, random_state = 15)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zG2UUghivu2V"
      },
      "outputs": [],
      "source": [
        "random.seed(100)\n",
        "import time\n",
        "\n",
        "#Empty dataframe to hold mean and median for each parameter combination\n",
        "fold_mses_df = pd.DataFrame(columns=['lambda','alpha','d','lasso','liulasso','goest','enet','kl1','ridge'])\n",
        "fold_med_df = pd.DataFrame(columns=['lambda','alpha','d','lasso','liulasso','goest','enet','kl1','ridge'])\n",
        "fold_times_df = pd.DataFrame(columns=['lambda','alpha','d','lasso','liulasso','goest','enet','kl1','ridge'])\n",
        "fold_medtime_df = pd.DataFrame(columns=['lambda','alpha','d','lasso','liulasso','goest','enet','kl1','ridge'])\n",
        "row_num = 1\n",
        "for lam in [0.1*(i+1) for i in range(10)]: #[0.1*(i+1) for i in range(9)]:\n",
        "  for a_p in [0.1*(i+1) for i in range(10)]:\n",
        "    for d_p in [0.1*(i+1) for i in range(10)]:\n",
        "      #Initiate empty list to hold mses for folds\n",
        "      msel_lasso, msel_liulasso, msel_goest, msel_enet = np.array([]), np.array([]), np.array([]), np.array([])\n",
        "      time_lasso, time_liulasso, time_goest, time_enet = np.array([]), np.array([]), np.array([]), np.array([])\n",
        "      msel_kl1, msel_ridge = np.array([]), np.array([])\n",
        "      time_kl1, time_ridge = np.array([]), np.array([])\n",
        "      kf3 = KFold(n_splits=10, shuffle=False)\n",
        "      sp = kf3.split(y)\n",
        "      for train_index, test_index in sp:\n",
        "        X_train=X[train_index,:]\n",
        "        y_train=y[train_index,:]\n",
        "        X_test=X[test_index,:]\n",
        "        y_test=y[test_index,:]\n",
        "        start1= time.time()\n",
        "        lasso_mod = coordinate_descent_lasso(X_train, y_train,lamda = lam, num_iters=100, intercept = False)\n",
        "        stop1= time.time()\n",
        "        start2= time.time()\n",
        "        liulasso_mod = coordinate_descent_liulasso(X_train, y_train, lamda = lam, d = d_p, num_iters=100, intercept = False)\n",
        "        stop2= time.time()\n",
        "        start3= time.time()\n",
        "        goest_mod = coordinate_descent_goest(X_train, y_train, lamda = lam, alpha = a_p, num_iters=100, intercept = False)\n",
        "        stop3= time.time()\n",
        "        start4= time.time()\n",
        "        enet_mod = coordinate_descent_enet(X_train, y_train, lamda = lam, alpha = a_p, num_iters=100, intercept = False)\n",
        "        stop4= time.time()\n",
        "        start5= time.time()\n",
        "        kl1_mod = coordinate_descent_KL1(X_train, y_train, lamda = lam, num_iters=100, intercept = False)\n",
        "        stop5= time.time()\n",
        "        start6= time.time()\n",
        "        ridge_mod = ridge_estimator(X_train, y_train, lamda = lam)\n",
        "        stop6= time.time()\n",
        "        msel_lasso = np.append(msel_lasso,np.square(np.subtract(y_test,X_test@lasso_mod)).mean())\n",
        "        msel_liulasso = np.append(msel_liulasso,np.square(np.subtract(y_test,X_test@liulasso_mod)).mean())\n",
        "        msel_goest = np.append(msel_goest,np.square(np.subtract(y_test,X_test@goest_mod)).mean())\n",
        "        msel_enet = np.append(msel_enet,np.square(np.subtract(y_test,X_test@enet_mod)).mean())\n",
        "        msel_kl1 = np.append(msel_kl1,np.square(np.subtract(y_test,X_test@kl1_mod)).mean())\n",
        "        msel_ridge = np.append(msel_ridge,np.square(np.subtract(y_test,X_test@ridge_mod)).mean())\n",
        "\n",
        "        time_lasso = np.append(time_lasso,np.subtract(stop1,start1).mean())\n",
        "        time_liulasso = np.append(time_liulasso,np.subtract(stop2,start2).mean())\n",
        "        time_goest = np.append(time_goest,np.subtract(stop3,start3).mean())\n",
        "        time_enet = np.append(time_enet,np.subtract(stop4,start4).mean())\n",
        "        time_kl1 =np.append(time_kl1,np.subtract(stop5,start5).mean())\n",
        "        time_ridge = np.append(time_ridge,np.subtract(stop6,start6).mean())\n",
        "\n",
        "      msel_lasso_mean, msel_liulasso_mean, msel_goest_mean, msel_enet_mean = np.mean(msel_lasso), np.mean(msel_liulasso), np.mean(msel_goest), np.mean(msel_enet)\n",
        "      msel_kl1_mean, msel_ridge_mean = np.mean(msel_kl1), np.mean(msel_ridge)\n",
        "      fold_mses_df.loc[row_num] = [lam,a_p,d_p,msel_lasso_mean, msel_liulasso_mean, msel_goest_mean, msel_enet_mean, msel_kl1_mean, msel_ridge_mean]\n",
        "\n",
        "      time_lasso_mean, time_liulasso_mean, time_goest_mean, time_enet_mean = np.mean(time_lasso), np.mean(time_liulasso), np.mean(time_goest), np.mean(time_enet)\n",
        "      time_kl1_mean, time_ridge_mean = np.mean(time_kl1), np.mean(time_ridge)\n",
        "      fold_times_df.loc[row_num] = [lam,a_p,d_p,time_lasso_mean, time_liulasso_mean, time_goest_mean, time_enet_mean, time_kl1_mean, time_ridge_mean]\n",
        "\n",
        "      msel_lasso_med, msel_liulasso_med, msel_goest_med, msel_enet_med = np.median(msel_lasso), np.median(msel_liulasso), np.median(msel_goest), np.median(msel_enet)\n",
        "      msel_kl1_med, msel_ridge_med = np.median(msel_kl1), np.median(msel_ridge)\n",
        "      fold_med_df.loc[row_num] = [lam,a_p,d_p,msel_lasso_med, msel_liulasso_med, msel_goest_med, msel_enet_med, msel_kl1_med, msel_ridge_med ]\n",
        "\n",
        "      time_lasso_med, time_liulasso_med, time_goest_med, time_enet_med = np.median(time_lasso), np.median(time_liulasso), np.median(time_goest), np.median(time_enet)\n",
        "      time_kl1_med, time_ridge_med = np.median(time_kl1), np.median(time_ridge)\n",
        "      fold_medtime_df.loc[row_num] = [lam,a_p,d_p,time_lasso_med, time_liulasso_med, time_goest_med, time_enet_med, time_kl1_med, time_ridge_med ]\n",
        "\n",
        "      row_num+=1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "V4TUIgwkvuls",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "1fd4fdf2-b8c0-456e-f16c-1a5c99a8935f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_577c20c0-6081-4133-83ff-bcabd837c6b8\", \"fold_mses_dff.csv\", 55)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_927e7c72-1683-464e-8d3e-a1bf2c01f37a\", \"fold_med_dff.csv\", 55)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "pd.DataFrame(fold_mses_df).to_csv('fold_mses_dff.csv', encoding = 'utf-8-sig')\n",
        "files.download('fold_mses_dff.csv')\n",
        "\n",
        "pd.DataFrame(fold_med_df).to_csv('fold_med_dff.csv', encoding = 'utf-8-sig')\n",
        "files.download('fold_med_dff.csv')\n",
        "\n",
        "pd.DataFrame(fold_times_df).to_csv('fold_times_dff.csv', encoding = 'utf-8-sig')\n",
        "files.download('fold_times_dff.csv')\n",
        "\n",
        "pd.DataFrame(fold_medtime_df).to_csv('fold_medtime_dff.csv', encoding = 'utf-8-sig')\n",
        "files.download('fold_metimed_dff.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hQ-ySspxkIt"
      },
      "outputs": [],
      "source": [
        "fold_mses_dff = files.upload()\n",
        "fold_mses_df = pd.read_csv(\"fold_mses_dff.csv\")\n",
        "\n",
        "fold_med_dff = files.upload()\n",
        "fold_med_df = pd.read_csv(\"fold_med_dff.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "GudtibMlNPrm"
      },
      "outputs": [],
      "source": [
        "fold_mses_df = fold_mses_df[['lambda','alpha','d','lasso','liulasso','goest','enet','kl1','ridge']]\n",
        "fold_med_df = fold_med_df[['lambda','alpha','d','lasso','liulasso','goest','enet','kl1','ridge']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "U79kNfu4xj1X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "outputId": "66b86d93-58da-491a-d4b3-a16720142a8e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-cf2d9736809e>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrow_no\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_estimators_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m  \u001b[0mggg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfold_mses_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold_mses_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mall_estimators_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m  \u001b[0mhyper_par_mse_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow_no\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mall_estimators_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mggg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mggg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m  \u001b[0mrow_no\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36midxmin\u001b[0;34m(self, axis, skipna, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m         \u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2494\u001b[0m         \"\"\"\n\u001b[0;32m-> 2495\u001b[0;31m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2497\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36margmin\u001b[0;34m(self, axis, skipna, *args, **kwargs)\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0;31m# error: Incompatible return value type (got \"Union[int, ndarray]\", expected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m             \u001b[0;31m# \"int\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m             return nanops.nanargmin(  # type: ignore[return-value]\n\u001b[0m\u001b[1;32m    718\u001b[0m                 \u001b[0mdelegate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mf_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nan\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 raise TypeError(\n\u001b[0m\u001b[1;32m     89\u001b[0m                     \u001b[0;34mf\"reduction operation '{f_name}' not allowed for this dtype\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 )\n",
            "\u001b[0;31mTypeError\u001b[0m: reduction operation 'argmin' not allowed for this dtype"
          ]
        }
      ],
      "source": [
        "all_estimators_names = ['lasso','liulasso','goest','enet','kl1','ridge']\n",
        "hyper_par_mse_df = pd.DataFrame(columns=['estimator','lambda','alpha','d','mse'])\n",
        "row_no = 1\n",
        "for i in range(len(all_estimators_names)):\n",
        " ggg = fold_mses_df.loc[fold_mses_df[all_estimators_names[i]].idxmin()].to_list()\n",
        " hyper_par_mse_df.loc[row_no] = [all_estimators_names[i]] + ggg[0:3] + [ggg[i+3]]\n",
        " row_no+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hTvy0h4x446"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(hyper_par_mse_df).to_csv('hyper_par_mse_dff.csv', encoding = 'utf-8-sig')\n",
        "files.download('hyper_par_mse_dff.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_j6vWVnyHf7"
      },
      "outputs": [],
      "source": [
        "hyper_par_mse_dff = files.upload()\n",
        "hyper_par_mse_df = pd.read_csv(\"hyper_par_mse_dff.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Elwz1jtPN4qj"
      },
      "outputs": [],
      "source": [
        "hyper_par_mse_df[['estimator','lambda','alpha','d','mse']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4PVAp4PyIwK"
      },
      "outputs": [],
      "source": [
        "xx_train, yy_train = X, y\n",
        "\n",
        "lam, d_p, a_p = fold_mses_df.loc[fold_mses_df[all_estimators_names[0]].idxmin()].to_list()[0:3]\n",
        "lasso_modt = coordinate_descent_lasso(xx_train, yy_train,lamda = lam, num_iters=100, intercept = False)\n",
        "\n",
        "lam, d_p, a_p = fold_mses_df.loc[fold_mses_df[all_estimators_names[1]].idxmin()].to_list()[0:3]\n",
        "liulasso_modt = coordinate_descent_liulasso(xx_train, yy_train, lamda = lam, d = d_p, num_iters=100, intercept = False)\n",
        "\n",
        "lam, d_p, a_p = fold_mses_df.loc[fold_mses_df[all_estimators_names[2]].idxmin()].to_list()[0:3]\n",
        "goest_modt = coordinate_descent_goest(xx_train, yy_train, lamda = lam, alpha = a_p, num_iters=100, intercept = False)\n",
        "\n",
        "lam, d_p, a_p = fold_mses_df.loc[fold_mses_df[all_estimators_names[3]].idxmin()].to_list()[0:3]\n",
        "enet_modt = coordinate_descent_enet(xx_train, yy_train, lamda = lam, alpha = a_p, num_iters=100, intercept = False)\n",
        "\n",
        "lam, d_p, a_p = fold_mses_df.loc[fold_mses_df[all_estimators_names[5]].idxmin()].to_list()[0:3]\n",
        "kl1_modt = coordinate_descent_KL1(xx_train, yy_train, lamda = lam, num_iters=100, intercept = False)\n",
        "\n",
        "lam, d_p, a_p = fold_mses_df.loc[fold_mses_df[all_estimators_names[10]].idxmin()].to_list()[0:3]\n",
        "ridge_modt = ridge_estimator(xx_train, yy_train, lamda = lam)\n",
        "\n",
        "mset_lasso = np.square(np.subtract(yy_test,xx_test@lasso_modt)).mean()\n",
        "mset_liulasso = np.square(np.subtract(yy_test,xx_test@liulasso_modt)).mean()\n",
        "mset_goest = np.square(np.subtract(yy_test,xx_test@goest_modt)).mean()\n",
        "mset_enet = np.square(np.subtract(yy_test,xx_test@enet_modt)).mean()\n",
        "mset_kl1 = np.square(np.subtract(yy_test,xx_test@kl1_modt)).mean()\n",
        "mset_ridge = np.square(np.subtract(yy_test,xx_test@ridge_modt)).mean()\n",
        "\n",
        "coeff_beta_modt = [lasso_modt,liulasso_modt,goest_modt,enet_modt,kl1_modt,ridge_modt]\n",
        "mse_test_beta_modt = [mset_lasso, mset_liulasso, mset_goest, mset_enet, mset_kl1, mset_ridge]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPoIXdUzyIYF"
      },
      "outputs": [],
      "source": [
        "#xx_test.shape[1]\n",
        "coeff_beta_modt_df = pd.DataFrame(coeff_beta_modt).transpose()\n",
        "var_name = ['x'+str(i) for i in range(xx_train.shape[1])]\n",
        "coeff_beta_modt_df.insert(loc=0, column='Variable', value=var_name)\n",
        "next_row = max(list(coeff_beta_modt_df.index.values)) + 1\n",
        "coeff_beta_modt_df.loc[next_row] = ['mses'] + mse_test_beta_modt\n",
        "coeff_beta_modt_df.columns = ['variable','lasso','liulasso','goest','enet','kl1','ridge']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xj7AznhbySQN"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(coeff_beta_modt_df).to_csv('coeff_beta_modt_dff.csv', encoding = 'utf-8-sig')\n",
        "files.download('coeff_beta_modt_dff.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAYB6dtjxjoV"
      },
      "outputs": [],
      "source": [
        "coeff_beta_modt_dff = files.upload()\n",
        "coeff_beta_modt_df = pd.read_csv(\"coeff_beta_modt_dff.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4sgriM2vnl6"
      },
      "outputs": [],
      "source": [
        "coeff_beta_modt_df[['variable','lasso','liulasso','goest','enet','kl1','ridge']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORqRFw6oOVdC"
      },
      "outputs": [],
      "source": [
        "#Empty dataframe to hold mean and median for each parameter combination\n",
        "fold_mses_df = pd.DataFrame(columns=['lambda','alpha','d','lasso','liulasso','goest','enet','kl1','ridge'])\n",
        "fold_med_df = pd.DataFrame(columns=['lambda','alpha','d','lasso','liulasso','goest','enet','kl1','ridge'])\n",
        "\n",
        "row_num = 1\n",
        "for lam in [0.1*(i+1) for i in range(10)]: #[0.1*(i+1) for i in range(9)]:\n",
        "  for a_p in [0.1*(i+1) for i in range(10)]:\n",
        "    for d_p in [0.1*(i+1) for i in range(10)]:\n",
        "      lasso_mod = coordinate_descent_lasso(xx_train, yy_train,lamda = lam, num_iters=100, intercept = False)\n",
        "      liulasso_mod = coordinate_descent_liulasso(xx_train, yy_train, lamda = lam, d = d_p, num_iters=100, intercept = False)\n",
        "      goest_mod = coordinate_descent_goest(xx_train, yy_train, lamda = lam, alpha = a_p, num_iters=100, intercept = False)\n",
        "      enet_mod = coordinate_descent_enet(xx_train, yy_train, lamda = lam, alpha = a_p, num_iters=100, intercept = False)\n",
        "      kl1_mod = coordinate_descent_KL1(xx_train, yy_train, lamda = lam, num_iters=100, intercept = False)\n",
        "      ridge_mod = ridge_estimator(xx_train, yy_train, lamda = lam)\n",
        "      msel_lasso = np.append(msel_lasso,np.square(np.subtract(y_test,X_test@lasso_mod)).mean())\n",
        "      msel_liulasso = np.append(msel_liulasso,np.square(np.subtract(y_test,X_test@liulasso_mod)).mean())\n",
        "      msel_goest = np.append(msel_goest,np.square(np.subtract(y_test,X_test@goest_mod)).mean())\n",
        "      msel_enet = np.append(msel_enet,np.square(np.subtract(y_test,X_test@enet_mod)).mean())\n",
        "      msel_kl1 = np.append(msel_kl1,np.square(np.subtract(y_test,X_test@kl1_mod)).mean())\n",
        "      msel_ridge = np.append(msel_ridge,np.square(np.subtract(y_test,X_test@ridge_mod)).mean())\n",
        "\n",
        "      msel_lasso_mean, msel_liulasso_mean, msel_goest_mean, msel_enet_mean = np.mean(msel_lasso), np.mean(msel_liulasso), np.mean(msel_goest), np.mean(msel_enet)\n",
        "      msel_kl1_mean, msel_ridge_mean = np.mean(msel_kl1), np.mean(msel_ridge)\n",
        "      fold_mses_df.loc[row_num] = [lam,a_p,d_p,msel_lasso_mean, msel_liulasso_mean, msel_goest_mean, msel_enet_mean,msel_kl1_mean, msel_ridge_mean]\n",
        "\n",
        "      msel_lasso_med, msel_liulasso_med, msel_goest_med, msel_enet_med = np.median(msel_lasso), np.median(msel_liulasso), np.median(msel_goest), np.median(msel_enet)\n",
        "      msel_kl1_med, msel_ridge_med = np.median(msel_kl1), np.median(msel_ridge)\n",
        "      fold_med_df.loc[row_num] = [lam,a_p,d_p,msel_lasso_med, msel_liulasso_med, msel_goest_med, msel_enet_med, msel_kl1_med, msel_ridge_med ]\n",
        "\n",
        "      row_num+=1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGOJlnnXLhy9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnwnZquZOVSk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}